# ğŸŒ‰ FlowGate â€” Smart API Rate Limiter & Gateway

FlowGate is a smart "gatekeeper" for your web services. It makes sure too many requests don't crash your server by putting them in a queue and letting them through at a safe, controlled pace.

---

## ğŸ¤” What Problem Does It Solve?

Imagine 100 people try to hit your API at once. Without a gatekeeper, your server crashes. FlowGate:
1. **Accepts every request immediately** â€” returns `202 Accepted` right away
2. **Puts them in a queue** (RabbitMQ) â€” like a waiting line
3. **Forwards them to your backend slowly and safely** â€” at exactly the rate you configure

---

## âœ¨ Key Features

| Feature | What it does |
|---|---|
| ğŸª£ **Token Bucket Rate Limiting** | Per API key. Tokens refill over time; each request uses one. |
| ğŸŒ **Global Rate Limiter** | Server-wide cap of 50 req/sec. Returns `503` if the whole system is too busy. |
| ğŸ“¬ **Async Queue (RabbitMQ)** | Requests are queued and consumed safely in the background. |
| ğŸ”‘ **Per-API-Key Control** | Each key has its own `capacity` (burst size) and `refillRate` (tokens/sec). |
| ğŸ‘¤ **User Accounts & JWT Auth** | Users register/login and manage only their own API keys. |
| ğŸ“Š **Live Status Dashboard** | See APIs as `ACTIVE`, `RATE_LIMITED`, or `INACTIVE` in real time. |
| ğŸ§¹ **Auto Redis Cleanup** | Stale rate-limit state is cleared automatically on startup. |

---

## ğŸ—ï¸ How It Works

```
[Client]
   â”‚  POST /proxy  +  X-API-Key header  +  JSON body { path, method, data }
   â–¼
[FlowGate Gateway :8080]
   â”œâ”€ Global rate limit check (50 req/sec) â†’ 503 if over
   â”œâ”€ Validate API key (Redis)             â†’ 401 if unknown
   â”œâ”€ Push to RabbitMQ queue              â†’ return 202 immediately
   â–¼
[ThrottleConsumer Worker]
   â”œâ”€ Reads capacity + refillRate from Redis
   â”œâ”€ Waits for a token (token bucket, Lua script)
   â””â”€ Forwards real request to backend
   â–¼
[Your Backend :9000]
```

---

## ğŸ§© Project Structure

```
FlowGate/
â”œâ”€â”€ application/          ğŸ§  Gateway (rate limiter + proxy + queue worker)
â”œâ”€â”€ UserRateLimiter/      ğŸ›ï¸  Management API (users + API key CRUD)
â”œâ”€â”€ user-rate-limiter-ui/ ğŸ–¥ï¸  React Dashboard
â”œâ”€â”€ demo/                 ğŸª Sample backend being protected
â””â”€â”€ load_test.py          ğŸ§ª Load testing script
```

---

## ğŸ”§ Two Types of Rate Limiting

### ğŸŒ Global Rate Limiter
- Checks **total** requests per second across all API keys
- Default limit: **50 req/sec**
- If exceeded â†’ `503 Service Unavailable` (before even checking the API key)

### ğŸª£ Per-Key Token Bucket
- Each API key has its own bucket of tokens
- Each request consumes 1 token; tokens refill at `refillRate` per second
- If bucket is empty, the worker waits until a token is available â€” no request is dropped

---

## ğŸ› ï¸ What You Need

| Tool | Purpose |
|---|---|
| **Java 17** | Runs the backend services |
| **Redis** | Stores rate limit state and API key configs |
| **RabbitMQ** | The message queue holding pending requests |
| **Node.js** | Runs the React dashboard (optional) |

---

## ğŸš€ Getting Started

### 1. Start the Sample Backend
```bash
cd demo
./mvnw.cmd spring-boot:run
# Runs on port 9000
```

### 2. Start the Management API
```bash
cd UserRateLimiter
./mvnw.cmd spring-boot:run
# Runs on port 8081
```

### 3. Start FlowGate Gateway
```bash
cd application
./mvnw.cmd spring-boot:run
# Runs on port 8080
```

### 4. (Optional) Start the Dashboard
```bash
cd user-rate-limiter-ui
npm install && npm run dev
# Opens at http://localhost:5173
```

---

## ğŸ”‘ Create Your First API Key

**Register:**
```http
POST http://localhost:8081/auth/register
Content-Type: application/json
{ "email": "you@example.com", "password": "yourpassword" }
```

**Login** (save the returned `token`):
```http
POST http://localhost:8081/auth/login
Content-Type: application/json
{ "email": "you@example.com", "password": "yourpassword" }
```

**Create an API key:**
```http
POST http://localhost:8081/apis
Authorization: Bearer <token>
Content-Type: application/json
{ "name": "My API", "targetUrl": "http://localhost:9000", "capacity": 10, "refillRate": 2 }
```
> Save the `apiKey` from the response!

**Or set one manually in Redis (quick test):**
```bash
hset api_key:MY_KEY capacity 10 refillRate 5 targetUrl http://localhost:9000
```

---

## ğŸ“¡ Sending Requests Through the Gateway

All requests go to **one single endpoint**: `POST /proxy`

The path and optional payload are sent in the **JSON body** â€” not in the URL.

### Request format
```http
POST http://localhost:8080/proxy
X-API-Key: <your-api-key>
Content-Type: application/json

{
  "path":   "/orders",
  "method": "POST",
  "data":   { "item": "book", "qty": 2 }
}
```

| Field | Required | Description |
|---|---|---|
| `path` | âœ… Yes | Endpoint to forward to (e.g. `/orders`) |
| `method` | âŒ Optional | HTTP verb â€” defaults to `POST` |
| `data` | âŒ Optional | Payload forwarded to your backend |

### Response
```
202 Accepted
Request accepted and queued -> POST http://localhost:9000/orders
```

---

## ğŸ§ª Load Testing

### PowerShell (send 20 requests at once)
```powershell
1..20 | ForEach-Object {
    $id = $_
    try {
        $body = @{ path = "/orders"; method = "POST"; data = @{ item = "book"; qty = 2 } } | ConvertTo-Json
        $resp = Invoke-RestMethod -Uri "http://localhost:8080/proxy" `
                                  -Method Post `
                                  -Headers @{"X-API-Key"="<your-api-key>"} `
                                  -Body $body `
                                  -ContentType "application/json"
        Write-Host "Request ${id}: Queued - $resp" -ForegroundColor Green
    } catch {
        $statusCode = $_.Exception.Response.StatusCode.value__
        Write-Host "Request ${id}: Failed ($statusCode)" -ForegroundColor Yellow
    }
}
```

### Python
```bash
python load_test.py
```

### What you'll see
- **All requests return `202`** instantly â€” they are queued, not rejected
- **In the gateway console:** requests forwarded one by one at your configured rate
- **If you send >50 req/sec:** some return `503` from the global limiter

---

## ğŸ“¡ API Reference

### Gateway â€” `application` (port 8080)
| Method | Endpoint | Description |
|---|---|---|
| `POST` | `/proxy` | Send a proxied request. Requires `X-API-Key` header + JSON body with `path`. |
| `POST` | `/rate-limit/check?key=X&capacity=10&refillRate=1` | Manually test if a key is allowed |

### Management API â€” `UserRateLimiter` (port 8081)
| Method | Endpoint | Description |
|---|---|---|
| `POST` | `/auth/register` | Register a new user |
| `POST` | `/auth/login` | Login and get JWT token |
| `POST` | `/apis` | Create an API key (JWT required) |
| `GET` | `/apis` | List your API keys with live status (JWT required) |

---

## ğŸ“Š API Key Status

| Status | Meaning |
|---|---|
| âœ… `ACTIVE` | Key exists in Redis, not being throttled |
| ğŸ”´ `RATE_LIMITED` | Token bucket empty â€” requests are waiting |
| âš« `INACTIVE` | Key not found in Redis |

---

## ğŸ§¹ Clearing State Between Tests

**Redis** (auto-cleared on startup):
```bash
redis-cli --scan --pattern "rate_limit:*" | xargs redis-cli del
redis-cli del global:rps
```

**RabbitMQ queue** â€” open **http://localhost:15672** â†’ Queues â†’ `throttle.queue.v2` â†’ **Purge Messages**

---

## âš ï¸ Common Fixes

| Problem | Fix |
|---|---|
| `Connection refused` | Make sure Redis and RabbitMQ are running |
| `400 Bad Request` from `/proxy` | Missing `path` field in your JSON body |
| `401` on `/proxy` | `X-API-Key` header is missing or not registered in Redis |
| `401` on `/apis` | Missing `Authorization: Bearer <token>` header |
| `503 Service Unavailable` | Hit the global 50 req/sec cap â€” slow down |
| `404` from demo backend | Make sure demo is running on port 9000 |
